#!/bin/bash

# jdk-link-harvester ( Coletor de link do jdk )
# Autor: Leonardo Bruno
# Contato: souzalb@proton.me
# Vers√£o: 1.0
# Data: 29/06/2025

# Verifica se o curl est√° instalado
if ! command -v curl &> /dev/null; then
    echo "‚ùå Erro: O comando 'curl' n√£o est√° instalado."
    echo "Por favor instale o curl para continuar:"
    echo ""
    echo "üì¶ Para sistemas baseados em Debian/Ubuntu:"
    echo "  sudo apt-get install curl"
    echo ""
    echo "üì¶ Para sistemas baseados em RHEL/CentOS:"
    echo "  sudo yum install curl"
    echo ""
    echo "üì¶ Para sistemas baseados em Arch:"
    echo "  sudo pacman -S curl"
    echo ""
    echo "üì¶ Para macOS (via Homebrew):"
    echo "  brew install curl"
    exit 1
fi

# URL base para download dos JDKs
BASE_URL="https://jdk.java.net/archive/"

# Extens√£o do arquivo desejado (bin√°rios Linux 64-bit)
EXTENSION="linux-x64_bin.tar.gz"

# Nome do arquivo de sa√≠da para salvar os links
OUTPUT_FILE="link-jdk.txt"

# Limpar o arquivo de sa√≠da (cria vazio ou sobrescreve existente)
> "$OUTPUT_FILE"

# Mensagem inicial
echo "üöÄ Iniciando busca em: $BASE_URL"
echo "üîç Procurando por arquivos .${EXTENSION}"
echo "‚è≥ Aguarde alguns instantes..."
echo "üìÅ Processando: ${BASE_URL}"

# Arquivo tempor√°rio para links encontrados
temp_links=$(mktemp)

# Arquivo temporario vers√µes processadas para ordena√ß√£o
temp_sorted=$(mktemp)

# Coletar links da p√°gina informada e filtra pela extens√£o desejada:
curl -s --compressed "$BASE_URL" | grep -oE 'href="[^"]*' | sed 's/href="//' | grep -E "$EXTENSION$" > "$temp_links"

# Contar o total de arquivos encontrados
total_files=$(wc -l < "$temp_links")

# Processar cada link para extrair a vers√£o do JDK
while IFS= read -r url; do
    # Extrair o nome do arquivo da URL
    filename=$(basename "$url")

    # Remo√ß√£o do prefixo 'openjdk-'
    version="${filename#openjdk-}"

    # Remo√ß√£o de tudo ap√≥s o primeiro underscore (_)
    version="${version%%_*}"
    
    # Formatar sa√≠da: vers√£o + tab + URL
    echo -e "$version\t$url"
done < "$temp_links" > "$temp_sorted"

# Ordenar por vers√£o e remover duplicatas:
# 1. sort -Vu: Ordena por vers√£o (-V) e remove duplicatas (-u)
# 2. -k1,1: Considera apenas a primeira coluna (vers√£o) para ordena√ß√£o
# 3. cut: Remove a coluna da vers√£o, mantendo apenas a URL
echo "üìä Ordenando por vers√£o e removendo duplicatas..."
sort -Vu -k1,1 "$temp_sorted" | cut -f2- > "$OUTPUT_FILE"

# Contar arquivos ap√≥s remo√ß√£o de duplicatas
total_files_after=$(wc -l < "$OUTPUT_FILE")

# Mostrar links ordenados ao usu√°rio
echo ""
echo "üìã Lista de links ordenados:"
while IFS= read -r link; do
    echo "  ‚úÖ $link"
done < "$OUTPUT_FILE"

# Remover arquivos tempor√°rios
rm "$temp_links" "$temp_sorted"

# Exibir relat√≥rio final
echo ""
echo "‚úÖ Busca conclu√≠da!"
echo "================================="
echo "üì¶ Arquivos encontrados:    $total_files"
echo "üîß Ap√≥s remover duplicatas: $total_files_after"
echo "üíæ Links salvos em:         $OUTPUT_FILE"
echo "================================="
